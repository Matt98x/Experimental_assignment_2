\href{http://htmlpreview.github.io/?https://github.com/Matt98x/Experimental_assignment1/blob/main/pet_package/html/index.html}{\tt Documentation}

\subsection*{Introduction}

This assignment target is to build an R\+OS architecture to implement a robot, simulating a pet, that interact with a human and moves in a discrete 2D environment. The pet has three states representing behaviours, that are simulated as a finite state machine with 3 states\+:
\begin{DoxyItemize}
\item Play
\item Sleep
\item Normal
\end{DoxyItemize}

These states determine the way the robot act inside the grid, whether moving randomly as in normal, going to targets determined by the user or simply sleeping in the home position.

The robot will change between states randomly, eccept for play, which is received by the user.

\subsection*{Software Architecture}

The software architecture consists in a pipeline, starting from the command generation and arriving to the pet simulation in turtlesim. Here we show the architecture image\+: 

$<$img src=\char`\"{}https\+://github.\+com/\+Matt98x/\+Experimental\+\_\+assignment1/blob/main/\+Images/\+Components\+\_\+diagram.\+P\+N\+G?raw=true \char`\"{}Title\char`\"{}\char`\"{}$>$ 

Component Diagram 

The main components are\+:


\begin{DoxyItemize}
\item Random command generator(\hyperlink{Command__giver_8py}{Command\+\_\+giver.\+py})-\/ send a string representing the concatenation of one or more commands of the form\+: \textquotesingle{}play\textquotesingle{}(to start the play state),\textquotesingle{}point to x y\textquotesingle{}(to simulate the pointing gesture to x y),\textquotesingle{}go to x y\textquotesingle{}(to simulate the voice command to x y)
\item Pet Interpreter(\hyperlink{Pet__logic_8py}{Pet\+\_\+logic.\+py})-\/ to interpret the string commands and translate them to a command list
\item Pet behaviours(\hyperlink{Pet__behaviours_8py}{Pet\+\_\+behaviours.\+py})-\/ that simulate behaviours as a finite state, in the already mentioned states
\item Turtle simulation-\/ that represents the position of the robot in the map
\item User-\/ may or may not be present and provides the same type of messages that the Command\+\_\+giver provides, adding also symbolical location such as \char`\"{}home\char`\"{} and \char`\"{}owner\char`\"{}
\end{DoxyItemize}

Starting from the Command\+\_\+giver, it is a publisher, with String type message, that transmit a series of 1 to 5 commands as the one discussed with a conjunction of an \char`\"{}and\char`\"{}.

Talking about the Pet interpreter, this component subscribes to the command generator topic and provides a service with share the value of the command string composed by integers and devided by the \textquotesingle{}$\vert$\textquotesingle{} character.

Now, we can discuss the finite state machine. This, can be described by the following image\+:

$<$img src=\char`\"{}https\+://github.\+com/\+Matt98x/\+Experimental\+\_\+assignment1/blob/main/\+Images/\+Finite\+\_\+state\+\_\+machines.\+P\+N\+G?raw=true \char`\"{}Title\char`\"{}\char`\"{}$>$ 

Finite state machine diagram 

While the \textquotesingle{}Sleep\textquotesingle{} and \textquotesingle{}Normal\textquotesingle{} state are quite simple in nature (containing just an infinite loop to sleep and to roam respectively), the \textquotesingle{}Play\textquotesingle{} state is quite more complex in nature, having the following structure\+: 

$<$img src=\char`\"{}https\+://github.\+com/\+Matt98x/\+Experimental\+\_\+assignment1/blob/main/\+Images/\+Play\+\_\+behaviour\+\_\+flowchart.\+P\+N\+G?raw=true \char`\"{}Title\char`\"{}\char`\"{}$>$ 

Play behaviour flowchart 

And finally the simulator node, which was not implemented by the outhors, but is the G\+UI that demonstrate the position of the robot during the pet activity.

\subsection*{Installation and running procedure}


\begin{DoxyItemize}
\item Download the package from the github repository
\item Set the package in the src folder of the catkin workspace
\item With the shell, get into the folder and run 
\begin{DoxyCode}
1 chmod +x launcher.sh
\end{DoxyCode}

\item Write 
\begin{DoxyCode}
1 ./launcher.sh
\end{DoxyCode}

\item You can look at the blue-\/background screen to obtain the graphical representation of the robot location, while, on the shell, the state transition and the command from the command menager are displayed
\item To write a command\+: 
\begin{DoxyCode}
1 rostopic pub /commander std\_msgs/String "data: ''" 
\end{DoxyCode}
 where, in place of \textquotesingle{}\textquotesingle{}, you can put any commands as presented before
\end{DoxyItemize}

\subsection*{Working assumptions}

The working assumptions will be discussed as the following list\+:
\begin{DoxyItemize}
\item The robot, simulating a pet, interact with a human and moves in a discrete 2D environment.
\item Both the robot targets and its positions belongs exclusively to the map(11 by 11 grid)representing the 2D environment.
\item The robot has 3 main states\+:
\begin{DoxyItemize}
\item Play
\item Normal
\item Sleep
\end{DoxyItemize}
\item The robot receive forms in strings with possible form\+:
\begin{DoxyItemize}
\item \char`\"{}play\char`\"{}
\item \char`\"{}go to x1 y1\char`\"{} (equivalent to voice command)
\item \char`\"{}point to x1 y1\char`\"{} (equivalent to pointing commands)
\item combination of commands with conjuctions of \char`\"{}and\char`\"{}\+:
\begin{DoxyItemize}
\item All the command after the play are executed
\item if a \char`\"{}play\char`\"{} is not in first place, only commands after the \char`\"{}play\char`\"{} command are executed
\end{DoxyItemize}
\end{DoxyItemize}
\item The robot can receive any command while executing one in Play state but the ones given are neither executed nor stored.
\item The robot can receive any command while in sleep state but the ones given are neither executed nor stored.
\item Sleep preempt any other state when it starts.
\item From Sleep you can only transition to Normal.
\item The only command that can be received in Normal is \char`\"{}play\char`\"{}.
\item Two predifined positions inside the map are \char`\"{}\+Owner\char`\"{} and \char`\"{}\+Home\char`\"{}, which cannot be changed during the execution, and can be used instead of coordinates in giving commands.
\end{DoxyItemize}

\subsection*{System features and limitations}

Starting from the limitations\+:
\begin{DoxyItemize}
\item The system is not scalable in the number of type of commands
\item It is not scalable in the number of symbolic locations
\item It is not really scalable in the number of states
\item Does not provide a complete graphical interface, as the grid is not visible
\item The simulation is not modifiable as it was out-\/sourced
\item Does not distinguish between the pointing action and the vocal command
\end{DoxyItemize}

Going on to the feature\+:
\begin{DoxyItemize}
\item Understand both integer and symbolic location, provided they are of the predefined nature
\item Can show the location of the robot in the map, provide, via shell, the state transition and the commands generated by the command generator
\item Can take any number of commands, even if the execution cannot be stopped if not by the random intervention by \hyperlink{Pet__logic_8py}{Pet\+\_\+logic.\+py}
\end{DoxyItemize}

\subsection*{Possible technical improvements}

There are many possible technical improvements to this architecture\+:
\begin{DoxyItemize}
\item Modify the simulation component to make it more scalable
\item Modify the interpreter to broaden the symbolic targets( to do it, the method is to setup a search in the parameters server to extract the coordinates related to the string)
\item Create a more comprehensive propositional logic, adding an \textquotesingle{}or\textquotesingle{} conjunction to make the system more intelligent
\item Add other states to the state machine, which implies also a modification of the \hyperlink{Pet__logic_8py}{Pet\+\_\+logic.\+py}
\item Make distinction between the pointing action and the vocal command
\end{DoxyItemize}

\subsection*{Author and contacts}

Matteo Palmas\+: matteo.\+palmas7gmail.\+com 